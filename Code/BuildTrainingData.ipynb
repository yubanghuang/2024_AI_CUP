{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "\n",
    "save_dir = 'ProcessedData'\n",
    "\n",
    "files = os.listdir('..//Data//OriginalData')\n",
    "files.sort(key=lambda x: int(x[1:x.index('_')]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_period(time_str):\n",
    "    time = datetime.strptime(time_str, \"%M:%S\").time()\n",
    "    \n",
    "    for period, (start, end) in periods.items():\n",
    "        if start <= time <= end:\n",
    "            return period\n",
    "    return None\n",
    "\n",
    "for file in files:\n",
    "    tokens = file.split('_')\n",
    "    file_name = tokens[0]\n",
    "    \n",
    "    data_df = pd.read_csv(f'..//Data//OriginalData//{file}')\n",
    "    \n",
    "    data_df['DateTime'] = pd.to_datetime(data_df['DateTime'])\n",
    "    data_df['Year'] = data_df['DateTime'].dt.year\n",
    "    data_df['Month'] = data_df['DateTime'].dt.month\n",
    "    data_df['Day'] = data_df['DateTime'].dt.day\n",
    "    data_df['Hour'] = data_df['DateTime'].dt.hour\n",
    "    data_df['Time'] = data_df['DateTime'].dt.strftime('%M:%S')\n",
    "\n",
    "    period = {\n",
    "        '00': (\"00:00\", \"09:59\"),\n",
    "        '10': (\"10:00\", \"19:59\"),\n",
    "        '20': (\"20:00\", \"29:59\"),\n",
    "        '30': (\"30:00\", \"39:59\"),\n",
    "        '40': (\"40:00\", \"49:59\"),\n",
    "        '50': (\"50:00\", \"59:59\")\n",
    "    }\n",
    "\n",
    "    periods = {\n",
    "        key: (\n",
    "            datetime.strptime(value[0], \"%M:%S\").time(),\n",
    "            datetime.strptime(value[1], \"%M:%S\").time()\n",
    "        )\n",
    "        for key, value in period.items()\n",
    "    }\n",
    "\n",
    "    data_df['Minute'] = data_df['Time'].apply(get_period)\n",
    "    \n",
    "    selected_features = [\n",
    "    'WindSpeed(m/s)',\n",
    "    'Pressure(hpa)',\n",
    "    'Temperature(Â°C)',\n",
    "    'Humidity(%)',\n",
    "    'Sunlight(Lux)',\n",
    "    'Power(mW)',\n",
    "    ]\n",
    "    \n",
    "    avg_df = data_df.groupby(['Year', 'Month', 'Day', 'Hour', 'Minute'])[selected_features].mean().round(2).reset_index()\n",
    "    avg_df.rename(columns=lambda x: \"Avg_\" + x if x in selected_features else x, inplace=True)\n",
    "    \n",
    "    max_df = data_df.groupby(['Year', 'Month', 'Day', 'Hour', 'Minute'])[selected_features].max().round(2).reset_index()\n",
    "    max_df.rename(columns=lambda x: \"Max_\" + x if x in selected_features else x, inplace=True)\n",
    "    \n",
    "    min_df = data_df.groupby(['Year', 'Month', 'Day', 'Hour', 'Minute'])[selected_features].min().round(2).reset_index()\n",
    "    min_df.rename(columns=lambda x: \"Min_\" + x if x in selected_features else x, inplace=True)\n",
    "    \n",
    "    processed_df = avg_df\n",
    "    processed_df = pd.merge(processed_df, min_df , how='inner')\n",
    "    processed_df = pd.merge(processed_df, max_df, how='inner' )\n",
    "    \n",
    "    device_id_df = data_df['LocationCode'].to_frame()\n",
    "    device_id_df.rename(columns={'LocationCode' : 'Device_ID'}, inplace=True)\n",
    "    \n",
    "    device_id_df = device_id_df.iloc[:len(processed_df)]\n",
    "    processed_df = pd.concat([device_id_df, processed_df], axis=1)\n",
    "    \n",
    "    processed_df.to_csv(f\"..//Data//{save_dir}//{file_name}_Processed_Train.csv\",index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_cup_2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
